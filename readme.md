# Hackatum 2019

We worked on the Microfuzzy’s challenge during the Hackatum 2019 @ Technical University of Munich.

## Our project

Our team worked in a project “X-Tunes”, which is to make a system to convert our body moment to sound and compose music.
We build up the sensors, collect data from it, and make up an algorithm to detect motion and put notes on it.

## Project structure

- Motion Recognition: we used Python to write the code for the motion recognition.
- Arduino Code: this folder contains the script that we used to fetch the data from the sensor using a bluetooth sensor
- Flask: in this folder you can find the code to build the rest api with the data collected from the sensor
- Images: here you can find some plots of the data collected by the sensor
- Visualization: we used React to visualize in a browser the data collected from the sensor
- Data: some data collected from the sensor.
- Pitch: this folder contains the slides from our presentation of "X-Tunes".

## Pitch

The slides from our presentation are available here
